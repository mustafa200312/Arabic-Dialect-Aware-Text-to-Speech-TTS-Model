{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import string\n",
    "import re\n",
    "import emoji\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COLLECTING DATASETS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine gathered dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./data/\"\n",
    "l = os.listdir(data_path)\n",
    "l_without_QADI = []\n",
    "for x in l:\n",
    "    if x[3:7] != \"QADI\":\n",
    "        l_without_QADI.append(x)\n",
    "l_without_QADI_dfs = []\n",
    "for x in l_without_QADI:\n",
    "    l_without_QADI_dfs.append(pd.read_csv(data_path+x))\n",
    "# add dialect label for each dataset\n",
    "for index, df in enumerate(l_without_QADI_dfs):\n",
    "    l_without_QADI_dfs[index]['dialect'] = l_without_QADI[index][:2]\n",
    "# drop unneeded columns\n",
    "for index, df in enumerate(l_without_QADI_dfs):\n",
    "    l_without_QADI_dfs[index].drop(columns=['Unnamed: 0'],inplace=True)\n",
    "all_dfs = pd.concat(l_without_QADI_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>dialect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1118821</th>\n",
       "      <td>به محل كتب هانا؟</td>\n",
       "      <td>YE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118822</th>\n",
       "      <td>شاحضر المدرسة الصيفية في جامعة هاواي.</td>\n",
       "      <td>YE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118823</th>\n",
       "      <td>منين بنخطى ذاحين؟</td>\n",
       "      <td>YE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118824</th>\n",
       "      <td>اثنين كبار وجاهل عمرة ثلاث سنين.</td>\n",
       "      <td>YE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118825</th>\n",
       "      <td>في حمام في المحطة.</td>\n",
       "      <td>YE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          text dialect\n",
       "1118821                       به محل كتب هانا؟      YE\n",
       "1118822  شاحضر المدرسة الصيفية في جامعة هاواي.      YE\n",
       "1118823                      منين بنخطى ذاحين؟      YE\n",
       "1118824       اثنين كبار وجاهل عمرة ثلاث سنين.      YE\n",
       "1118825                     في حمام في المحطة.      YE"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_dfs.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_list = stopwords.words('arabic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_for_each_line(tweet):\n",
    "    \"\"\"\"\n",
    "    Remove stop words\n",
    "    Remove emotions\n",
    "    Remove numbers\n",
    "    Remove any non-arabic characters\n",
    "    Normalize Arabic words\n",
    "    Remove mentions\n",
    "    Remove Links\n",
    "    \"\"\"\n",
    "    tweet = str(tweet)\n",
    "    tweet = re.sub(r\"(?:\\@|http?s?://|www)\\S+\", \" \", tweet)\n",
    "    tweet = re.sub(r'&amp;|&quot;|&gt;', ' ', tweet)\n",
    "    tweet = re.sub(r'(.)\\1+', r'\\1', tweet)\n",
    "    tweet = re.sub(r'[^اأإآء-ي0-9\\s]', ' ', tweet) \n",
    "    tweet = re.sub(r'[0-9]+', ' ', tweet)\n",
    "    tweet = emoji.demojize(tweet, language='ar')\n",
    "    tweet = tweet.replace(\"#\", \" \").replace(\"_\", \" \")\n",
    "    tweet = ' '.join([word for word in word_tokenize(tweet) if word not in stopwords_list])\n",
    "    tweet = re.sub(r'[إأآا]', 'ا', tweet)\n",
    "    tweet = re.sub(r'ة', 'ه', tweet)\n",
    "    tweet = re.sub(r'ى', 'ي', tweet)\n",
    "    return tweet.strip()\n",
    "\n",
    "def remove_punctuation(tweet):\n",
    "    \"\"\"\n",
    "    Remove arabic and English punctuation marks\n",
    "    \"\"\"\n",
    "    arabic_punctuations = '''`÷×؛<>_()*&^%][ـ،/:\"؟.,'{}~¦+|!”…“–ـ'''\n",
    "    english_punctuations = string.punctuation\n",
    "    punctuations = arabic_punctuations + english_punctuations\n",
    "    translator = str.maketrans('', '', punctuations)\n",
    "    return tweet.translate(translator)\n",
    "\n",
    "def cleaning(df):\n",
    "    \"\"\"\"\n",
    "    Apply data cleaning\n",
    "    \"\"\"\n",
    "    df['text'] = df['text'].apply(cleaning_for_each_line)\n",
    "    df['text'] = df['text'].apply(remove_punctuation)\n",
    "    df['text'] = df['text'].str.replace('’', ' ', regex=False)\n",
    "    df['text'] = df['text'].str.replace(r'[\\s\\n\\t]+', ' ', regex=True).str.strip()\n",
    "    df = df.dropna(subset=['text'])\n",
    "    df = df[df['text'].str.strip().astype(bool)]\n",
    "    df = df.drop_duplicates()\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do data cleaning\n",
    "all_dfs = cleaning(all_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_27964\\2978365983.py:2: DtypeWarning: Columns (0,1,2,6,8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  other_df = pd.read_csv(\"arabic_dialects_clean.csv\")\n"
     ]
    }
   ],
   "source": [
    "# Combine 2 datasets\n",
    "other_df = pd.read_csv(\"arabic_dialects_clean.csv\")\n",
    "other_df = other_df[['text','dialect']]\n",
    "l = list(other_df.dialect.value_counts().keys())[:18]\n",
    "other_df = other_df[other_df['dialect'].isin(l)]\n",
    "other_df = cleaning(other_df)\n",
    "all_dfs = pd.concat([all_dfs, other_df], ignore_index=True)\n",
    "all_dfs = cleaning(all_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dialect\n",
       "DZ    154832\n",
       "EG    133236\n",
       "SA    105368\n",
       "AE    103124\n",
       "BH     78597\n",
       "LB     62433\n",
       "SY     62009\n",
       "KW     55882\n",
       "PL     54279\n",
       "JO     53092\n",
       "TN     52674\n",
       "LY     39487\n",
       "QA     33004\n",
       "SD     31903\n",
       "OM     26962\n",
       "IQ     20966\n",
       "YE     11868\n",
       "MA     11533\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_dfs.dialect.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "qadi = pd.read_csv('QADI.csv')\n",
    "qadi = qadi[['text','label']]\n",
    "qadi = cleaning(qadi)\n",
    "qadi.rename(columns={'label': 'dialect'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "map={0:'OM', 1:'SD', 2:'SA', 3:'KW', 4:'QA', 5:'LB', 6:'JO', 7:'SY', 8:'IQ', 9:'MA', 10:'EG', 11:'PL', 12:'YE', 13:'BH', 14:'DZ', \n",
    "     15:'AE', 16:'TN', 17:'LY'}\n",
    "qadi['dialect'] = qadi['dialect'].map(map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_Data = pd.concat([all_dfs, qadi], ignore_index=True)\n",
    "all_Data = cleaning(all_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dialect\n",
       "DZ    154851\n",
       "EG    133236\n",
       "SA    105446\n",
       "AE    103145\n",
       "BH     78629\n",
       "LB     62433\n",
       "SY     62036\n",
       "KW     55909\n",
       "PL     54301\n",
       "JO     53109\n",
       "TN     52713\n",
       "LY     39487\n",
       "QA     33031\n",
       "SD     31903\n",
       "OM     26990\n",
       "IQ     20976\n",
       "YE     11882\n",
       "MA     11533\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_Data.dialect.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1091610, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_Data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_Data.to_csv(\"COLLECTED_DATA_2.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
